{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Assignment 4\n",
    "\n",
    "**Submission deadline: last classes before 13.04.2016**\n",
    "\n",
    "**Points: 11 + 1 bonus points**\n",
    "\n",
    "\n",
    "## Downloading this notebook\n",
    "\n",
    "This assignment is an Jupyter notebook. Download it by cloning https://github.com/janchorowski/nn_assignments. Follow the instructions in its README for instructions.\n",
    "\n",
    "For programming exerciese add your solutions to the notebook. For math exercies please provide us with answers on paper or type them in the notebook i supports Latex-like equations).\n",
    "\n",
    "Please do not hesitate to use GitHubâ€™s pull requests to send us corrections!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as sopt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "\n",
    "from common.gradients import check_gradient, numerical_gradient, encode_params, decode_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the following assignments let:\n",
    " * $X \\in \\mathbb{R}^{k\\times N}$ be the data matrix containing $N$\n",
    "  samples each described with $k$ features. The $i$-th sample $x^{(i)} \\in\n",
    "  \\mathbb{R}^{(k\\times 1)}$ is the $i$-th column of $X$.\n",
    " * $Y \\in \\mathbb{R}^{1\\times N}$ be the row-vector of targets,\n",
    "  with $y^{(i)}$ being the target for the $i$-th sample.\n",
    " * $\\Theta\\in\\mathbb{R}^{k\\times 1}$ be the vector of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 1 (Backpropagation through a tanh neuron) [2p]\n",
    "\n",
    "  We want to use a single neuron with the $\\tanh(x) = \\frac{e^x -\n",
    "    e^{-x}}{e^x + e^{-x}}$ activation function.\n",
    "  First find the derivative $\\frac{\\partial \\tanh(x)}{\\partial\n",
    "    x}$ and express it as a function of $\\tanh(x)$.\n",
    "  Forward computations performed by the neuron are:\n",
    "  \n",
    "  \\begin{align*}\n",
    "    A &= \\Theta^T X \\\\\n",
    "    \\hat{Y} &= \\tanh(A) \\text{ applied elementwise} \\\\\n",
    "    E &= Y - \\hat{Y} \\\\\n",
    "    J &= E \\cdot E^T\n",
    "  \\end{align*}\n",
    "  \n",
    "  Find and express using matrix notation the following gradients. You\n",
    "  can refer to values and gradients computed earlier in the expressions for the\n",
    "  following ones -- just as you would when implementing a computer\n",
    "  program. Use $\\odot$ for the elementwise multiplication of matrices.\n",
    "\n",
    "  \\begin{align*}\n",
    "    \\frac{\\partial J}{\\partial E } &= ? \\\\\n",
    "    \\frac{\\partial J}{\\partial \\hat{Y}} &= ? \\\\\n",
    "    \\frac{\\partial J}{\\partial A} &= ? \\\\\n",
    "    \\frac{\\partial J}{\\partial \\Theta} &= ? \\\\\n",
    "  \\end{align*}\n",
    "  \n",
    "  **Note:** each gradient above should be implementable as a\n",
    "  compact expression in Python+NumPy.\n",
    "\n",
    "  **Hint:** write down the shapes of all values that you\n",
    "  compute. Work out the expressions for a single element of the\n",
    "  gradient, then see how they can be expressed using the matrix\n",
    "  notation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**1)**\n",
    "\n",
    "From last week:\n",
    "\n",
    "$\\frac{\\partial \\tanh(x)}{\\partial x} = 1 - \\tanh^2(x) $\n",
    "\n",
    "**2)**\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial J}{\\partial E } &= 2 E \\\\\n",
    "    \\frac{\\partial J}{\\partial \\hat{Y}} &= (-1) \\frac{\\partial J}{\\partial E } \\\\\n",
    "    \\frac{\\partial J}{\\partial A} &= \\frac{\\partial J}{\\partial \\hat{Y}} \\odot (1 - \\tanh^2(A)) \\\\\n",
    "    \\frac{\\partial J}{\\partial \\Theta} &= \\frac{\\partial J}{\\partial A} X^T \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## SoftMax Regression\n",
    "\n",
    "The samples in the Iris dataset belong to one of three classes, while in\n",
    "CIFAR10 and MNIST they belong to one of 10 classes. Thus, linear regression cannot be\n",
    "applied because it distinguishes between two classes only.\n",
    "We will use SoftMax regression instead.\n",
    "\n",
    "Let $x\\in \\mathbb{R}^n$ be a sample vector and\n",
    "$y\\in \\{1,2,\\ldots,K\\}$ its class label.\n",
    "Similarly to what has been done during the lecture,\n",
    "we extend vector $x$ with the bias term $x_0=1$ to simplify the calculations\n",
    "(so now $x\\in \\mathbb{R}^{n+1}$).\n",
    "\n",
    "In SoftMax regression, we model conditional probability, that \n",
    "a given sample $x$ belongs to class $k$. Such model is parametrized\n",
    "with a matrix $\\Theta\\in\\mathbb{R}^{K \\times n+1}$.\n",
    "Note that in SoftMax regression, a separate linear model is build for each\n",
    "class. First we compute the vector $a$ of total inputs:\n",
    "\\begin{equation}\n",
    "a_k = \\sum_{j=0}^{n}\\Theta_{k,j}x_j,\n",
    "\\end{equation}\n",
    "or using matrix notation $a = \\Theta x$.\n",
    "Then we compute conditional probabilities using SoftMax regression:\n",
    "\\begin{equation}\n",
    "p(\\text{class}=k|x, \\Theta)= o_k = \\frac{\\exp{a_k}}{\\sum_{j=1}^K \\exp{a_j}}.\n",
    "\\end{equation}\n",
    "\n",
    "Function SoftMax transforms a $K$-element vector of real numbers\n",
    "to a vector of non-negative numbers which sum to 1. Thus they can be\n",
    "treated as probabilities assigned to $K$ separate classes.\n",
    "\n",
    "As it is the case with linear regression, we use cross-entropy\n",
    "as the loss function in SoftMax regression:\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "J^{(i)}(\\Theta) &= - \\sum_{k=1}^{K} [y^{(i)}=k]\\log o_k^{(i)} \\\\\n",
    "J(\\Theta) &= \\frac{1}{m}\\sum_{i=1}^m J^{(i)}(\\Theta)= -\\frac{1}{m}\\sum_{i=1}^m\\sum_{k=1}^{K} [y^{(i)}=k]\\log o_k^{(i)} \n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "where $[y^{(i)}=k]$ equals $1$ when the $i-$th sample belongs to class $k$,\n",
    "and $0$ otherwise.\n",
    "Value $[y^{(i)}=k]$ might be interpreted as the correct value of the $k$-th\n",
    "output of the model on sample $i$.\n",
    "In addition, the total loss is expressed as a mean loss of particular samples,\n",
    "to make it independent of the size of the training set.\n",
    "\n",
    "Loss function gradient with respect to total inputs $a$ is simple:\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial J^{(i)}}{\\partial a^{(i)}_k} = o_k^{(i)} - [y^{(i)}=k].\n",
    "\\end{equation}\n",
    "\n",
    "Using the chain rule, the gradient of the loss function with respect to\n",
    "model parameters becomes:\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial J}{\\partial \\Theta_{kj}} = \\sum_{i=1}^m \\frac{\\partial J}{\\partial J^{(i)}}\\frac{\\partial J^{(i)}}{\\partial \\Theta_{kj}} = \\sum_{i=1}^m \\frac{1}{m}\\cdot \\frac{\\partial J^{(i)}}{\\partial a^{(i)}_k} \\frac{\\partial a^{(i)}_k}{\\partial \\Theta_{kj}} = \\frac{1}{m}\\sum_{i=1}^m \\frac{\\partial J^{(i)}}{\\partial a^{(i)}_k} x^{(i)}_j.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 2 [2p]\n",
    "  Implement SoftMax regression and apply it to the Iris dataset.\n",
    "  During training, use L-BFGS from `scipy.optimize`. You can initialize the algorithm\n",
    "  with a null matrix (all entries being zeros).\n",
    "  Obtained accuracy should be comparable with that of k-NN\n",
    "  (roughly 3% of errors).\n",
    "  If your model doesn't work, check the gradient using the `check_gradient`\n",
    "  routine from the Starter Code of Assignment 3, which computes the gradient numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IrisXFull is a (5, 150)-shaped matrix of float64\n",
      "IrisX2feats is a (3, 150)-shaped matrix of float64\n",
      "IrisY is a (1, 150)-shaped matrix of int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f4aefe324d0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiUAAAF5CAYAAABAyVr6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4aefeaa450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# Here we load the IRIS dataset.\n",
    "# We will create two datasets: one using all features, and one using just Petal Langth and Petal Width for visualizations\n",
    "#\n",
    "iris = datasets.load_iris()\n",
    "petal_length = iris.data[:,iris.feature_names.index('petal length (cm)')]\n",
    "petal_width = iris.data[:, iris.feature_names.index('petal width (cm)')]\n",
    "\n",
    "IrisXFull = np.vstack([np.ones_like(petal_length), iris.data.T])\n",
    "IrisX2feats = np.vstack([np.ones_like(petal_length), petal_length, petal_width])\n",
    "IrisY = iris.target.reshape(1,-1).astype(np.int64)\n",
    "\n",
    "print((\"IrisXFull is a %s-shaped matrix of %s\" % (IrisXFull.shape, IrisXFull.dtype)))\n",
    "print((\"IrisX2feats is a %s-shaped matrix of %s\" % (IrisX2feats.shape, IrisX2feats.dtype)))\n",
    "print((\"IrisY is a %s-shaped matrix of %s\" % (IrisY.shape, IrisY.dtype)))\n",
    "\n",
    "scatter(IrisX2feats[1,:], IrisX2feats[2,:], c=IrisY.ravel(), cmap='spring')\n",
    "xlabel('petal_length')\n",
    "ylabel('petal_width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def SoftMaxRegression_implementation(ThetaFlat, X, Y=None, return_probabilities=False):\n",
    "    \"\"\"\n",
    "    Compute the outputs of a softmax classifier, or the loss and gradient\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ThetaFlat : \n",
    "        flat array of parameters containing (n_features*n_classes) entries\n",
    "    X :\n",
    "        array of features, shape n_features x n_smaples\n",
    "    Y :\n",
    "        optional array of desired targets of shape 1 x n_samples\n",
    "    return_probabilities : \n",
    "        if True, the probabilities are returned and Y is not used\n",
    "        if False, the los and gradient is computed on the X,Y pairs\n",
    "    \"\"\"\n",
    "    #X is num_features x num_samples\n",
    "    num_features, num_samples = X.shape\n",
    "    if Y is not None:\n",
    "        assert(Y.shape == (1,num_samples))\n",
    "\n",
    "    #Theta is num_features x num_classes\n",
    "    #we first reshape ThetaFlat into Theta\n",
    "    Theta = ThetaFlat.reshape(num_features, -1)\n",
    "    num_classes = Theta.shape[1]\n",
    "\n",
    "    #Activation of softmax neurons\n",
    "    #A's shape should be num_classes x num_samples\n",
    "    A = Theta.T.dot(X)\n",
    "    \n",
    "    #Stability optimization - for each subtract the maximum activation\n",
    "    A -= A.max(0, keepdims=True)\n",
    "    \n",
    "    #Now compute the SoftMax function\n",
    "    #O will be a num_classes x num_samples matrix of probabilities assigned by our model  \n",
    "    O = np.exp(A)\n",
    "    s = np.sum(O, axis=0)\n",
    "    O /= s\n",
    "\n",
    "    if return_probabilities:\n",
    "        return O\n",
    "    \n",
    "    #The loss is the average per-sample nll (neg log likelihood)\n",
    "    #The nll is the sum of the logarithms of probabilities assigned to each class\n",
    "    correct_class_likelihoods = np.log(O[Y.ravel(), np.arange(num_samples)])\n",
    "    L = - 1.0/num_samples * np.sum(correct_class_likelihoods)\n",
    "\n",
    "    #For the softmax activation and cross-entropy loss, the derivative dNLL/dA has a simple form\n",
    "    #Please fill in its computation\n",
    "    conditional = Y == np.arange(num_classes).reshape(-1,1)\n",
    "    dLdA = 1.0/num_samples * (O - conditional)\n",
    "\n",
    "    #Now we compute the gradient of the loss with respect to Theta\n",
    "    dLdTheta = np.dot(X, dLdA.T)\n",
    "\n",
    "    #reshape gard into the shape of Theta, for fmin_l_bfsgb to work\n",
    "    return L, dLdTheta.reshape(ThetaFlat.shape)\n",
    "\n",
    "#Make a function for training on irises\n",
    "iris_log_reg_cost = lambda Theta: SoftMaxRegression_implementation(Theta, IrisXFull, IrisY, False)\n",
    "#Make sure that the gradient computation is OK\n",
    "check_gradient(iris_log_reg_cost, np.zeros((3*5,)))\n",
    "check_gradient(iris_log_reg_cost, np.random.rand(3*5)*2.0-1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Call a solver\n",
    "#\n",
    "\n",
    "#iprint will cause the solver to print TO THE TERMINAL from which ipython notebook was started\n",
    "ThetaOpt = sopt.fmin_l_bfgs_b(iris_log_reg_cost, np.zeros((3*5,)), iprint=1)[0]\n",
    "\n",
    "check_gradient(iris_log_reg_cost, ThetaOpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accurracy: 98.666667%\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Compute training errors\n",
    "#\n",
    "\n",
    "probabilities = SoftMaxRegression_implementation(ThetaOpt, IrisXFull, return_probabilities=True)\n",
    "predictions = np.argmax(probabilities,0)\n",
    "\n",
    "print((\"Training accurracy: %f%%\" % ((predictions==IrisY.ravel()).mean()*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accurracy: 96.000000%\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Now redo the training for two features\n",
    "\n",
    "iris_log_reg_cost = lambda Theta: SoftMaxRegression_implementation(Theta, IrisX2feats, IrisY, False)\n",
    "\n",
    "Theta2class = sopt.fmin_l_bfgs_b(iris_log_reg_cost, np.zeros((3*3,)), iprint=1)[0]\n",
    "check_gradient(iris_log_reg_cost, Theta2class)\n",
    "\n",
    "probabilities = SoftMaxRegression_implementation(Theta2class, IrisX2feats, return_probabilities=True)\n",
    "predictions = np.argmax(probabilities,0)\n",
    "\n",
    "print((\"Training accurracy: %f%%\" % ((predictions==IrisY.ravel()).mean()*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Now plot the decision boundary\n",
    "# \n",
    "\n",
    "petal_lengths, petal_widths = np.meshgrid(np.linspace(IrisX2feats[1,:].min(), IrisX2feats[1,:].max(), 100),\n",
    "                                          np.linspace(IrisX2feats[2,:].min(), IrisX2feats[2,:].max(), 100))\n",
    "\n",
    "IrisXGrid = np.vstack([np.ones(np.prod(petal_lengths.shape)), petal_lengths.ravel(), petal_widths.ravel()])\n",
    "predictions_Grid = SoftMaxRegression_implementation(Theta2class, IrisXGrid, return_probabilities=True).argmax(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f4aefc6afd0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAGHCAYAAAAHoqCrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4aefcfd250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "contourf(petal_lengths, petal_widths, predictions_Grid.reshape(petal_lengths.shape), cmap='spring')\n",
    "scatter(IrisX2feats[1,:], IrisX2feats[2,:], c=IrisY.ravel())\n",
    "xlabel('petal_length')\n",
    "ylabel('petal_width')\n",
    "title('Decision boundary found by SoftMAX regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2-layer Neural Network\n",
    "\n",
    "The task is to extend the SoftMax regression model to a 2-layer neural net.\n",
    "The network will transform an input vector to an activation vector\n",
    "of hidden neurons and finally, using the SoftMax function,\n",
    "to a vector of probabilities of the sample's belonging to one of 10 classes.\n",
    "\n",
    "To train the network, we'll need the loss function $J$ and its gradient\n",
    "with respect to network's parameters (weights and biases).\n",
    "For a 2-layer net, this can be achieved using the following relationships:\n",
    "\n",
    "### Data\n",
    "\n",
    "The training set has $m$ samples of $n$ dimensions, belonging to one\n",
    "of $K$ classes, it is given as a set of matrices: $X \\in \\mathbb{R}^{n\\times m}$\n",
    "and $Y\\in \\{1,2,\\ldots,K\\}^{1\\times m}$.\n",
    "\n",
    "### Parameters\n",
    "\n",
    "The net will have 2 layers: 1) a hidden one, having $L$ neurons,\n",
    "and 2) an output one, having $K$ neurons (one for each of $K$ classes).\n",
    "The layers are defined through:\n",
    "\n",
    "\n",
    "1. the parameters of the hidden layer, which maps $n$-dimensional input vectors\n",
    "  into activations of $L$ neurons:\n",
    "  weight matrix $W^h\\in\\mathbb{R}^{L\\times n}$ and bias vector\n",
    "  $b^h\\in\\mathbb{R}^{L\\times 1}$,\n",
    "  \n",
    "2. the parameters of the output layer, which maps $L$-dimensional vector\n",
    "  of activations of the hidden layer to $K$ activations of output neurons:\n",
    "  weight matrix $W^o\\in{K\\times L}$ and bias vector $b^o\\in\\mathbb{R}^{K\\times 1}$.\n",
    "\n",
    "### Signal forward propagation (fprop)\n",
    "\n",
    "Each hidden neuron computes its total input as a sum of product of its\n",
    "inputs, weight matrix and bias. For an $i$-th sample,\n",
    "the total input\n",
    "${a^{h}}^{(i)}_l $ of an $I$-th neuron is thus:\n",
    "\\begin{equation}\n",
    "{a^h}^{(i)}_l = \\sum_{j=1}^n {W^h}_{l,j}x^{(i)}_j + {b^h}_l\n",
    "\\end{equation}\n",
    "The total input of neurons might also be expressed via matrices,\n",
    "using matrix multiplication and broadcasting (which allows to add\n",
    "a column vector to all column vectors of a matrix):\n",
    "\\begin{equation}\n",
    "{a^h} = W^h\\cdot x + b^h\n",
    "\\end{equation}\n",
    "This can be implemented in Python as `ah = W.dot(x) + b`.\n",
    "\n",
    "Next, we compute activation $h^h$ of hidden neurons with hyperbolic tangent\n",
    "$\\tanh(a) = \\frac{e^a-e^{-a}}{e^a+e^{-a}}$:\n",
    "\\begin{equation}\n",
    "{h^h}^{(i)}_l=\\tanh({a^h}^{(i)}_l)\n",
    "\\end{equation}\n",
    "Thanks to vectorization in Python + numpy, $h^h$ might be computed with a single\n",
    "expression `hh = numpy.tanh(ah)`.\n",
    "\n",
    "Total input of the output layer can be computed using\n",
    "activations of the hidden layer (with the help of broadcasting) as:\n",
    "\n",
    "\\begin{equation}\n",
    "a^o = W^o\\cdot h^h + b^o\n",
    "\\end{equation}\n",
    "\n",
    "Finally, probabilities of a sample's belonging to  particular classes\n",
    "have to be computed. This can be achieved with SoftMax:\n",
    "\n",
    "\\begin{equation}\n",
    "    p(y^{(i)}=k|x^{(i)}) = o^{(i)}_k = \\frac{\\exp({a^o}^{(i)}_k)}{ \\sum_{k'=1}^K \\exp( {a^o}^{(i)}_{k'} )}.\n",
    "\\end{equation}\n",
    "\n",
    "Like with SoftMax regression, we will use cross-entropy\n",
    "as the loss function:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "J^{(i)}(\\Theta) &= - \\sum_{k=1}^{K} [y^{(i)}=k]\\log o_k^{(i)}, \\\\\n",
    "J(\\Theta) &= \\frac{1}{m}\\sum_{i=1}^m J^{(i)}(\\Theta)= -\\frac{1}{m}\\sum_{i=1}^n\\sum_{k=1}^{K} [y^{(i)}=k]\\log o_k^{(i)}.\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "### Error backpropagation (bprop)\n",
    "\n",
    "Using the chain rule one can derive the gradient of the loss function\n",
    "in respect to neurons' activations and network parameters.\n",
    "\n",
    "\n",
    "First we compute the gradient with respect to the output layer's\n",
    "total inputs:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial J}{\\partial {a^o}^{(i)}_k} = \\frac{1}{m}(o_k^{(i)} - [y^{(i)}=k]),\n",
    "\\end{equation}\n",
    "\n",
    "then we compute the gradient with respect to activations of hidden units:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial J}{\\partial {h^h}^{(i)}_l} = \\sum_{k=1}^K \\frac{\\partial J}{\\partial {a^o}^{(i)}_k} \\frac{\\partial {a^o}^{(i)}_k}{\\partial {h^h}^{(i)}_l} =  \\sum_{k=1}^K \\frac{\\partial J}{\\partial {a^o}^{(i)}_k} {W^o}_{kl},\n",
    "\\end{equation}\n",
    "then we compute the gradient with respect to the total activations of hidden units:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial J}{\\partial {a^h}^{(i)}_l} = \\frac{\\partial J}{\\partial {h^h}^{(i)}_l}\\frac{\\partial {h^h}^{(i)}_l}{\\partial {a^h}^{(i)}_l} = \\frac{\\partial J}{\\partial {h^h}^{(i)}_l} (1 - ({h^h}^{(i)}_l)^2),\n",
    "\\end{equation}\n",
    "\n",
    "where we have used the relationship\n",
    "\n",
    "$\\frac{\\partial \\tanh(x)}{\\partial x} = 1-\\tanh(x)^2$.\n",
    "\n",
    "Finally we can use the gradients with respect to the total inputs to\n",
    "compute the gradients with respect to network parameters,\n",
    "eg. for the input layer:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial J}{\\partial {W^o}_{kl}} = \\sum_{i}\\frac{\\partial J}{\\partial {a^o}^{(i)}_k}\\frac{\\partial {a^o}^{(i)}_k}{\\partial {W^o}_{kl}} = \\sum_{i}\\frac{\\partial J}{\\partial {a^o}^{(i)}_k}{h^h}^{(i)}_l,\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial J}{\\partial {b^o}_{k}} = \\sum_{i}\\frac{\\partial J}{\\partial {a^o}^{(i)}_k}\\frac{\\partial {a^o}^{(i)}_k}{\\partial {b^o}_{k}} = \\sum_{i}\\frac{\\partial J}{\\partial {a^o}^{(i)}_k}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 3 [2p]\n",
    "  Implement a 2-layer neural network as a function\n",
    "  **TwoLayerNet($\\Theta$,X,Y)**\n",
    "  which computes the loss and gradient of loss with\n",
    "  respect to the weights and bias terms (encoded as $\\Theta$)\n",
    "  on data given as $X$ and $Y$.\n",
    "  Refer to the Starter Code below for the details.\n",
    "  Try to express as much as possible with matrix calculus.\n",
    "\n",
    "  The following problems will require to train the network.\n",
    "  Use the L-BFGS optimizer from `scipy.optimize` to minimize\n",
    "  your function (particularly: the loss) and find the right $\\Theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def TwoLayerNet_implementation(ThetaFlat, ThetaShapes, X, Y=None, return_probabilities=False):\n",
    "    \"\"\"\n",
    "    Compute the outputs of a softmax classifier, or the loss and gradient\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ThetaFlat : \n",
    "        flat array of parameters\n",
    "    ThetaShapes :\n",
    "        list of shapes of weight and bias matrices\n",
    "    X :\n",
    "        array of features, shape n_features x n_smaples\n",
    "    Y :\n",
    "        optional array of desired targets of shape 1 x n_samples\n",
    "    return_probabilities : \n",
    "        if True, the probabilities are returned and Y is not used\n",
    "        if False, the los and gradient is computed on the X,Y pairs\n",
    "    \"\"\"\n",
    "    #X is num_features x num_samples\n",
    "    num_features, num_samples = X.shape\n",
    "    if Y is not None:\n",
    "        assert(Y.shape == (1,num_samples))\n",
    "    \n",
    "    #Extract weight matrices\n",
    "    W1, W2 = decode_params(ThetaFlat, ThetaShapes)\n",
    "    \n",
    "    X_padded = np.vstack([np.ones((1, num_samples)), X])\n",
    "    \n",
    "    #Activation in first layer. Shape is num_hidden x num_samples\n",
    "    A1 = W1.T.dot(X_padded)\n",
    "    \n",
    "    #Apply the transfer function\n",
    "    H1 = np.tanh(A1)\n",
    "        \n",
    "    #Pad with zeros\n",
    "    H1_padded = np.vstack([np.ones((1, num_samples)), H1])\n",
    "    \n",
    "    #Now apply the second linear transform\n",
    "    # shape: num_classes x num_samples\n",
    "    A2 = W2.T.dot(H1_padded)\n",
    "    \n",
    "    #Stability optimization - for each subtract the maximum activation\n",
    "    A2 -= A2.max(0, keepdims=True)\n",
    "    \n",
    "    #Now compute the SoftMax function\n",
    "    #O will be a num_classes x num_samples matrix of probabilities assigned by our model  \n",
    "    O = np.exp(A2)\n",
    "    s = np.sum(O, axis=0)\n",
    "    O /= s\n",
    "    \n",
    "    if return_probabilities:\n",
    "        return O\n",
    "    \n",
    "    #The loss is the average per-sample nll (neg log likelihood)\n",
    "    #The nll is the sum of the logarithms of probabilities assigned to each class\n",
    "    correct_class_likelihoods = np.log(O[Y.ravel(), np.arange(num_samples)])\n",
    "    L = - 1.0/num_samples * np.sum(correct_class_likelihoods)\n",
    "\n",
    "    #For the softmax activation and cross-entropy loss, the derivative dNLL/dA has a simple form\n",
    "    #Please fill in its computation\n",
    "    conditional = Y == np.arange(num_classes).reshape(-1,1)\n",
    "    dLdA2 = 1.0/num_samples * (O - conditional)\n",
    "\n",
    "    dLdH1_padded = W2.dot(dLdA2)\n",
    "    dLdH1 = dLdH1_padded[1:,:] #ship the derivatives backpropagated to the added ones\n",
    "    \n",
    "    # dLdA1 = dLdH1 * (1.0 - tanh(A1)**2)\n",
    "    dLdA1 = dLdH1 * (1.0 - H1**2)\n",
    "    \n",
    "    # compute the derivatives dLdW2 and dLdW1\n",
    "    # Hint - to compute dLdW1, start with dLdA1\n",
    "    dLdW2 = np.dot(H1, dLdA2.T)\n",
    "    dLdW2 = np.vstack([np.sum(dLdA2, axis=1).reshape(1,-1) , dLdW2])\n",
    "    dLdW1 = np.dot(X, dLdA1.T)\n",
    "    dLdW1 = np.vstack([np.sum(dLdA1, axis=1).reshape(1,-1) , dLdW1])\n",
    "\n",
    "    #reshape gard into the shape of Theta, for fmin_l_bfsgb to work\n",
    "    dLdThetaFlat, unused_shapes = encode_params([dLdW1, dLdW2])\n",
    "    \n",
    "    return L, dLdThetaFlat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 4 [1p] (choosing the initial vector)\n",
    "  In the cases of linear and logistic regression,\n",
    "  we could start the optimization with a vector of zeros.\n",
    "  Such initialization will be troublesome for neural networks.\n",
    "\n",
    "  You can use the following initialization methods for\n",
    "  network parameters: a) initialize weight matrices with small random\n",
    "  numbers (eg. drawn from $\\mathcal{N}(0, 0.2)$), b) initialize bias\n",
    "  vectors with zeros. Train the network on the Iris dataset and report\n",
    "  classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Here we init the network for gradient testing on IRIS\n",
    "#\n",
    "# We will have 7 hidden neurons.\n",
    "# The first weight matrix will be 5 (4 features + bias) x 7 (hidden neurons)\n",
    "# The second weight matrix will be 8 (7 neurons + bias) x 3 (classes)\n",
    "#\n",
    "num_hidden = 7\n",
    "\n",
    "num_features = 4\n",
    "num_classes = 3\n",
    "\n",
    "W1 = np.random.normal(0, 0.2, size=(num_features+1, num_hidden)) \n",
    "W2 = np.random.normal(0, 0.2, size=(num_hidden+1, num_classes)) \n",
    "\n",
    "# Now flatten into an array\n",
    "Theta0, ThetaShape = encode_params([W1,W2])\n",
    "\n",
    "#Make a function for training on irises\n",
    "iris_net_cost = lambda Theta: TwoLayerNet_implementation(Theta, ThetaShape, iris.data.T, IrisY, False)\n",
    "#Make sure that the gradient computation is OK\n",
    "check_gradient(iris_net_cost, Theta0)\n",
    "check_gradient(iris_net_cost, np.zeros_like(Theta0))\n",
    "check_gradient(iris_net_cost, np.ones_like(Theta0)*0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accurracy: 99.333333%\n"
     ]
    }
   ],
   "source": [
    "# apply L-BFGS to minimize the loss and get optimal ThetaOpt.\n",
    "\n",
    "ThetaOpt = sopt.fmin_l_bfgs_b(iris_net_cost, Theta0, iprint=1)[0]\n",
    "check_gradient(iris_net_cost, ThetaOpt)\n",
    "\n",
    "predictions = TwoLayerNet_implementation(ThetaOpt, ThetaShape, iris.data.T, return_probabilities=True).argmax(0)\n",
    "print((\"Training accurracy: %f%%\" % ((predictions==IrisY.ravel()).mean()*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 5 [1p + 1p bonus]\n",
    "\n",
    "### XOR network\n",
    "Test your network on a 2-dimensional and a 3-dimensional\n",
    "XOR problem. How many hidden neurons the network requires to express\n",
    "the XOR function?\n",
    "\n",
    "### Iris network\n",
    "Normalize the Iris dataset, so that each of the 4 attributes\n",
    "would fall into {[}-1,1{]} interval. Train the network and check classification\n",
    "accuracy.\n",
    "\n",
    "### Bonus\n",
    "Plot samples (for XOR or for Iris) in hidden neurons' activation space\n",
    "(similarly to http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/).\n",
    "\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "XOR2X = np.array([[0,0],\n",
    "                  [0,1],\n",
    "                  [1,0],\n",
    "                  [1,1]]).T\n",
    "XOR2Y = np.array([[0,1,1,0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#init the neurons\n",
    "num_samples = XOR2X.shape[1]\n",
    "num_features = XOR2X.shape[0]\n",
    "num_classes = 2\n",
    "num_hidden = 2\n",
    "W1 = (np.random.rand(num_features+1,num_hidden) - 0.5)\n",
    "W2 = (np.random.rand(num_hidden+1,num_classes) - 0.5)\n",
    "\n",
    "# Now flatten into an array\n",
    "Theta0, ThetaShape = encode_params([W1,W2])\n",
    "\n",
    "# apply L-BFGS to minimize the loss and get optimal ThetaOpt.\n",
    "xor2d_net_cost = lambda Theta: TwoLayerNet_implementation(Theta, ThetaShape, XOR2X, XOR2Y, False)\n",
    "ThetaOpt = sopt.fmin_l_bfgs_b(xor2d_net_cost, Theta0, iprint=1)[0]\n",
    "\n",
    "predictions = TwoLayerNet_implementation(ThetaOpt, ThetaShape, XOR2X, return_probabilities=True).argmax(0)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  1.  1.  1.  1.]\n",
      " [ 0.  0.  1.  1.  0.  0.  1.  1.]\n",
      " [ 0.  1.  0.  1.  0.  1.  0.  1.]]\n",
      "[[0 1 1 0 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# repeat the experiment for 3-dimensional XOR.\n",
    "\n",
    "XOR3X = np.hstack([\n",
    "    np.vstack([np.zeros(4), XOR2X]),\n",
    "    np.vstack([np.ones(4), XOR2X]),\n",
    "])\n",
    "XOR3Y = (np.sum(XOR3X, axis=0, dtype='Int16') % 2).reshape(1,-1)\n",
    "\n",
    "print(XOR3X)\n",
    "print(XOR3Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#init the neurons\n",
    "num_samples = XOR3X.shape[1]\n",
    "num_features = XOR3X.shape[0]\n",
    "num_classes = 2\n",
    "num_hidden = 3 # didnt work with 2 hidden neurons\n",
    "W1 = (np.random.rand(num_features+1,num_hidden) - 0.5)\n",
    "W2 = (np.random.rand(num_hidden+1,num_classes) -0.5)\n",
    "\n",
    "# Now flatten into an array\n",
    "Theta0, ThetaShape = encode_params([W1,W2])\n",
    "\n",
    "# apply L-BFGS to minimize the loss and get optimal ThetaOpt.\n",
    "xor3d_net_cost = lambda Theta: TwoLayerNet_implementation(Theta, ThetaShape, XOR3X, XOR3Y, False)\n",
    "ThetaOpt = sopt.fmin_l_bfgs_b(xor3d_net_cost, Theta0, iprint=1)[0]\n",
    "\n",
    "predictions = TwoLayerNet_implementation(ThetaOpt, ThetaShape, XOR3X, return_probabilities=True).argmax(0)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# (Bonus)\n",
    "# TODO - change network implementation code to return hidden activations.\n",
    "# Hint - locals() gives the dictionary of all objects in a functions's scope!\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# normalize IrisNormX, so the vaues would fall into [-1,1].\n",
    "IrisNormX = np.array(iris.data.T)\n",
    "m = np.min(IrisNormX)\n",
    "M = np.max(IrisNormX)\n",
    "r = M-m\n",
    "IrisNormX = (IrisNormX - m) / r # in [0,1]\n",
    "IrisNormX = 2.0 * IrisNormX - 1.0 # in [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accurracy: 99.333333%\n"
     ]
    }
   ],
   "source": [
    "num_hidden = 10\n",
    "\n",
    "num_features = IrisNormX.shape[0]\n",
    "num_classes = 3\n",
    "\n",
    "W1 = (np.random.rand(num_features + 1, num_hidden) - 0.5)*0.1\n",
    "W2 = (np.random.rand(num_hidden + 1, num_classes) - 0.5)*0.1\n",
    "\n",
    "# Now flatten into an array\n",
    "Theta0, ThetaShape = encode_params([W1, W2])\n",
    "\n",
    "iris_net_cost = lambda Theta: TwoLayerNet_implementation(Theta, ThetaShape, IrisNormX, IrisY, False)\n",
    "ThetaOpt = sopt.fmin_l_bfgs_b(iris_net_cost, Theta0, iprint=1)[0]\n",
    "\n",
    "predictions = TwoLayerNet_implementation(ThetaOpt, ThetaShape, IrisNormX, return_probabilities=True).argmax(0)\n",
    "print((\"Training accurracy: %f%%\" % ((predictions==IrisY.ravel()).mean()*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 6 [1p]\n",
    "\n",
    "  Final questions:\n",
    "  \n",
    "   * Are neural networks parametric (https://en.wikipedia.org/wiki/Parametric_model) or non-parametric (https://en.wikipedia.org/wiki/Non-parametric_model) models? Why is it so?\n",
    "   \n",
    "   * What will happen if for each layer (hidden and output) all weights\n",
    "    will be initialized to the same values before the training?\n",
    "    \n",
    "   * How will the value of SoftMax function change,\n",
    "  if we will add the same constant term to each element of $a$?\n",
    "  Often, before computing SoftMax, the largest value can be subtracted\n",
    "  to mitigate large exponents and associated numerical errors.\n",
    "  Is it a good practice?\n",
    "\n",
    "   * Are two-class SoftMax regression and logistic regression equivalent (can you build a logistic regression model from a given softmax one and vice versa)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 7 [1p]\n",
    "You are provided with a starter code for a modular implementation of a\n",
    "feedforward neural network. Your general task is to fill in the blanks\n",
    "in the code, and validate the implementation on the IRIS task (ake sure\n",
    "that the network can be trained on the Iris dataset to reach 100% training\n",
    "accuracy.)\n",
    "\n",
    "**Note:** the next assignment list will involve using this code, or other neural \n",
    "network implementation that you will be able to fully explain to reach a low\n",
    "error rate on the mnist dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# These are taken from https://github.com/mila-udem/blocks\n",
    "# \n",
    "\n",
    "class Constant():\n",
    "    \"\"\"Initialize parameters to a constant.\n",
    "    The constant may be a scalar or a :class:`~numpy.ndarray` of any shape\n",
    "    that is broadcastable with the requested parameter arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    constant : :class:`~numpy.ndarray`\n",
    "        The initialization value to use. Must be a scalar or an ndarray (or\n",
    "        compatible object, such as a nested list) that has a shape that is\n",
    "        broadcastable with any shape requested by `initialize`.\n",
    "    \"\"\"\n",
    "    def __init__(self, constant):\n",
    "        self._constant = numpy.asarray(constant)\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        dest = numpy.empty(shape, dtype=np.float32)\n",
    "        dest[...] = self._constant\n",
    "        return dest\n",
    "\n",
    "\n",
    "class IsotropicGaussian():\n",
    "    \"\"\"Initialize parameters from an isotropic Gaussian distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    std : float, optional\n",
    "        The standard deviation of the Gaussian distribution. Defaults to 1.\n",
    "    mean : float, optional\n",
    "        The mean of the Gaussian distribution. Defaults to 0\n",
    "    Notes\n",
    "    -----\n",
    "    Be careful: the standard deviation goes first and the mean goes\n",
    "    second!\n",
    "    \"\"\"\n",
    "    def __init__(self, std=1, mean=0):\n",
    "        self._mean = mean\n",
    "        self._std = std\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        m = rng.normal(self._mean, self._std, size=shape)\n",
    "        return m.astype(np.float32)\n",
    "\n",
    "\n",
    "class Uniform():\n",
    "    \"\"\"Initialize parameters from a uniform distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    mean : float, optional\n",
    "        The mean of the uniform distribution (i.e. the center of mass for\n",
    "        the density function); Defaults to 0.\n",
    "    width : float, optional\n",
    "        One way of specifying the range of the uniform distribution. The\n",
    "        support will be [mean - width/2, mean + width/2]. **Exactly one**\n",
    "        of `width` or `std` must be specified.\n",
    "    std : float, optional\n",
    "        An alternative method of specifying the range of the uniform\n",
    "        distribution. Chooses the width of the uniform such that random\n",
    "        variates will have a desired standard deviation. **Exactly one** of\n",
    "        `width` or `std` must be specified.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean=0., width=None, std=None):\n",
    "        if (width is not None) == (std is not None):\n",
    "            raise ValueError(\"must specify width or std, \"\n",
    "                             \"but not both\")\n",
    "        if std is not None:\n",
    "            # Variance of a uniform is 1/12 * width^2\n",
    "            self._width = numpy.sqrt(12) * std\n",
    "        else:\n",
    "            self._width = width\n",
    "        self._mean = mean\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        w = self._width / 2\n",
    "        m = rng.uniform(self._mean - w, self._mean + w, size=shape)\n",
    "        return m.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self, rng=None):\n",
    "        if rng is None:\n",
    "            rng = numpy.random\n",
    "        self.rng = rng\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "    @property\n",
    "    def parameter_names(self):\n",
    "        return []\n",
    "    \n",
    "    def get_gradients(self, dLdY, fprop_context):\n",
    "        return []\n",
    "    \n",
    "\n",
    "class AffineLayer(Layer):\n",
    "    def __init__(self, num_in, num_out, weight_init=None, bias_init=None, **kwargs):\n",
    "        super(AffineLayer, self).__init__(**kwargs)\n",
    "        if weight_init is None:\n",
    "            #\n",
    "            # TODO propose a default initialization scheme.\n",
    "            # Type a sentence explaining why, and if you use a reference, \n",
    "            # cite it here\n",
    "            #\n",
    "            weight_init = TODO\n",
    "        if bias_init is None:\n",
    "            bias_init = Constant(0.0)\n",
    "        \n",
    "        self.W = weight_init.generate(self.rng, (num_out, num_in))\n",
    "        self.b = bias_init.generate(self.rng, (num_out, 1))\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return [self.W, self.b]\n",
    "    \n",
    "    @property\n",
    "    def parameter_names(self):\n",
    "        return ['W','b']\n",
    "    \n",
    "    def fprop(self, X):\n",
    "        #Save X for later reusal\n",
    "        fprop_context = dict(X=X)\n",
    "        Y = np.dot(self.W, X) +  self.b\n",
    "        return Y, fprop_context\n",
    "    \n",
    "    def bprop(self, dLdY, fprop_context):\n",
    "        #\n",
    "        # TODO: fill in gradient computation\n",
    "        #\n",
    "        dLdX = TODO\n",
    "        return dLdX\n",
    "    \n",
    "    def get_gradients(self, dLdY, fprop_context):\n",
    "        X = fprop_context['X']\n",
    "        dLdW = np.dot(dLdY, X.T)\n",
    "        dLdb = dLdY.sum(1, keepdims=True)\n",
    "        return [dLdW, dLdb]\n",
    "    \n",
    "class TanhLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(TanhLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def fprop(self, X):\n",
    "        Y = np.tanh(X)\n",
    "        fprop_context = dict(Y=Y)\n",
    "        return Y, fprop_context\n",
    "    \n",
    "    def bprop(self, dLdY, fprop_context):\n",
    "        Y = fprop_context['Y']\n",
    "        #\n",
    "        # Fill in proper gradient computation\n",
    "        #\n",
    "        return TODO\n",
    "\n",
    "    \n",
    "class ReLULayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReLULayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def fprop(self, X):\n",
    "        Y = np.maximum(X, 0.0)\n",
    "        fprop_context = dict(Y=Y)\n",
    "        return Y, fprop_context\n",
    "    \n",
    "    def bprop(self, dLdY, fprop_context):\n",
    "        Y = fprop_context['Y']\n",
    "        return dLdY * (Y>0)\n",
    "\n",
    "    \n",
    "class SoftMaxLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SoftMaxLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def compute_probabilities(self, X):\n",
    "        O = X - X.max(axis=0, keepdims=True)\n",
    "        O = np.exp(O)\n",
    "        O /= O.sum(axis=0, keepdims=True)\n",
    "        return O\n",
    "    \n",
    "    def fprop_cost(self, X, Y):\n",
    "        NS = X.shape[1]\n",
    "        O = self.compute_probabilities(X)\n",
    "        Cost = -1.0/NS * np.log(O[Y.ravel(), list(range(NS))]).sum()\n",
    "        return Cost, O, dict(O=O, X=X, Y=Y)\n",
    "    \n",
    "    def bprop_cost(self, fprop_context):\n",
    "        X = fprop_context['X']\n",
    "        Y = fprop_context['Y']\n",
    "        O = fprop_context['O']\n",
    "        NS = X.shape[1]\n",
    "        dLdX = O.copy()\n",
    "        dLdX[Y, list(range(NS))] -= 1.0\n",
    "        dLdX /= NS\n",
    "        return dLdX\n",
    "    \n",
    "class FeedForwardNet(object):\n",
    "    def __init__(self, layers=None):\n",
    "        if layers is None:\n",
    "            layers = []\n",
    "        self.layers = layers\n",
    "    \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for layer in self.layers:\n",
    "            params += layer.parameters\n",
    "        return params\n",
    "    \n",
    "    @parameters.setter\n",
    "    def parameters(self, values):\n",
    "        for ownP, newP in zip(self.parameters, values):\n",
    "            ownP[...] = newP\n",
    "    \n",
    "    @property\n",
    "    def parameter_names(self):\n",
    "        param_names = []\n",
    "        for layer in self.layers:\n",
    "            param_names += layer.parameter_names\n",
    "        return param_names\n",
    "    \n",
    "    def fprop(self, X):\n",
    "        for layer in self.layers[:-1]:\n",
    "            X, fp_context = layer.fprop(X)\n",
    "        return self.layers[-1].compute_probabilities(X)\n",
    "    \n",
    "    def get_cost_and_gradient(self, X, Y):\n",
    "        fp_contexts = []\n",
    "        for layer in self.layers[:-1]:\n",
    "            X, fp_context = layer.fprop(X)\n",
    "            fp_contexts.append(fp_context)\n",
    "        \n",
    "        L, O, fp_context = self.layers[-1].fprop_cost(X, Y)\n",
    "        dLdX = self.layers[-1].bprop_cost(fp_context)\n",
    "        \n",
    "        dLdP = [] #gradient with respect to parameters\n",
    "        for i in range(len(self.layers)-1):\n",
    "            layer = self.layers[len(self.layers)-2-i]\n",
    "            fp_context = fp_contexts[len(self.layers)-2-i]\n",
    "            dLdP = layer.get_gradients(dLdX, fp_context) + dLdP\n",
    "            dLdX = layer.bprop(dLdX, fp_context)\n",
    "        return L, O, dLdP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#training algorithms. They change the network!\n",
    "def GD(net, X, Y, alpha=1e-4, max_iters=1000000, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Simple batch gradient descent\n",
    "    \"\"\"\n",
    "    old_L = np.inf\n",
    "    for i in range(max_iters):\n",
    "        L, O, gradients = net.get_cost_and_gradient(X, Y)\n",
    "        if old_L < L:\n",
    "            print((\"Iter: %d, loss increased!!\" % (i,)))\n",
    "        if (old_L - L)<tolerance:\n",
    "            print(\"Tolerance level reached exiting\")\n",
    "            break\n",
    "        if i % 1000 == 0:\n",
    "            err_rate = (O.argmax(0) != Y).mean()\n",
    "            print((\"At iteration %d, loss %f, train error rate %f%%\" % (i, L, err_rate*100)))\n",
    "        for P,G in zip(net.parameters, gradients):\n",
    "            P -= alpha * G\n",
    "        old_L = L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "IrisX = iris.data.T\n",
    "IrisX = (IrisX - IrisX.mean(axis=1, keepdims=True)) / IrisX.std(axis=1, keepdims=True)\n",
    "IrisY = iris.target.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'TODO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-62982dba8af5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m net = FeedForwardNet([\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mAffineLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mTanhLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mAffineLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-eee59d363700>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, num_in, num_out, weight_init, bias_init, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m# cite it here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mweight_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTODO\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias_init\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mbias_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'TODO' is not defined"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Here we verify that the network can be trained on Irises.\n",
    "# Most runs should result in 100% accurracy\n",
    "#\n",
    "\n",
    "net = FeedForwardNet([\n",
    "        AffineLayer(4,10),\n",
    "        TanhLayer(),\n",
    "        AffineLayer(10,3),\n",
    "        SoftMaxLayer()\n",
    "        ])\n",
    "GD(net, IrisX,IrisY, 1e-1, tolerance=1e-7, max_iters=50000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
